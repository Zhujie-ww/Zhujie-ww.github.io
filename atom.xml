<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xblearncs</title>
  
  <subtitle>Never Stop Going!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhujie-ww.github.io/"/>
  <updated>2020-04-19T08:30:40.753Z</updated>
  <id>https://zhujie-ww.github.io/</id>
  
  <author>
    <name>xiaobai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习之数学基础</title>
    <link href="https://zhujie-ww.github.io/posts/1003/"/>
    <id>https://zhujie-ww.github.io/posts/1003/</id>
    <published>2020-04-19T01:29:08.487Z</published>
    <updated>2020-04-19T08:30:40.753Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 align="center">概述</h1><p>1、什么是机器学习？</p><blockquote><p>机器学习是从经验中学习，建立模型从而进行决策与预测，简言之从经验中获取知识；</p></blockquote><p>2、机器学习数学基础包含几部分？</p><blockquote><p>包含微积分（优化方法）、线性代数、统计学、信息论；具体而言：</p><blockquote><p>微积分：<br>梯度、凸函数、牛顿法、梯度下降法；<br>线性代数：<br>特征向量、矩阵分解；<br>统计学：<br>描述统计与统计推断（正态总体、其他总体）（ 频率派 vs 贝叶斯学派）<br>信息论：<br>信息熵、交叉熵、互信息、$KL散度$；</p></blockquote></blockquote><p>3、机器学习的数学学习方法？</p><blockquote><p>先入门基本的数学知识，然后在机器学习<code>实战</code>中需要数学的时候再去<code>有目的的补充</code>；</p><p>学习方法：<code>**重视概念理解，轻数学证明，多多与他人交流！**</code></p></blockquote><h1 align="center">微积分部分</h1><p>1、导数的作用？</p><blockquote><p>链式法则是神经网络反向传播基础；<br>梯度求导则是梯度下降法优化方法的基础；</p></blockquote><p>2、求导方法？</p><blockquote><p>分为向量对x求导、矩阵对x求导、y关于向量求导、向量y关于向量x求导（又被称为雅可比矩阵）（看成向量y对xi标量求导）、海森矩阵（$$Hessian{\rm{ = }}{{{\partial ^2}f(x)} \over {\partial x\partial {x^T}}}$$）；</p></blockquote><p>3、优化？</p><blockquote><p>定义：在约束条件下求解目标函数最值；</p><p>方法：<br>① 梯度下降法（最速下降法）：如下山朝着最抖的地方下山最快；</p></blockquote><p>梯度方向：增长最快的方向；如果求最大值，朝着梯度方向，反之朝着反方向；</p><p>公式描述：$${a_{k + 1}} = {a_k} + step \cdot {{ - \nabla f({x_i})} \over {\left| {\nabla f({x_i})} \right|}}$$</p><p>存在问题：如果步长太长，容易发散，反之则收敛速度太慢；</p><p><code>改进方法：BGD(批量梯度下降)/SGD(随机梯度下降)/**MBGD(小批量梯度下降)**</code></p><p>② 牛顿法：</p><p>思想：泰勒展开为二次函数，用后者的极值点代替原极值点；</p><p>特点：收敛快、计算量大；</p><h1 align="center">线性代数部分</h1><h2 align="center">向量</h2><p>1、几何意义？</p><blockquote><p>向量为空间中的点/有向线段，向量加法可以看成有向路径，为二者之和；</p></blockquote><p>2、向量内积？</p><blockquote><p>几何意义：投影；</p><blockquote><p>点乘用途：常用于判断两个向量的相似程度，如两部电影A,B，二者都有特征电影价格、导演、好评度、票房，通过A,B点乘的夹角可以看出二者相似程度；</p></blockquote></blockquote><p>3、向量范数？</p><blockquote><p>第一范数：$\sum {\left| {{x_i}} \right|} $<br>第二范数：模长<br>第三范数：$Max(\left| {{x_i}} \right|)$</p><p>作用： 判断两个特征向量的相似程序，广泛用于无监督学习！</p></blockquote><h2 align="center">矩阵</h2><p>1、如何看待矩阵？</p><blockquote><p>矩阵==数表；<br>矩阵==列/行向量张成的向量空间；<br>矩阵==线性变换，如旋转、压缩、剪切变换，特别的初等矩阵对应一个初等变换；<br>矩阵==线性方程组，如电流系统、经济系统、化学方程；</p></blockquote><p>2、如何看待矩阵乘法$C = AB$？</p><blockquote><p>视角0：函数（变换），矩阵乘以向量表示对向量进行线性变换，如同$$y = f(x)$$</p></blockquote><p>视角1：点积（几何平面求交点问题）：${C_{ij}} = {A_i}{B_j}$；</p><p>视角2：列向量/行向量的线性组合；<br>视角3：列行矩阵：<br>$$\sum {\left( {\matrix{   a  \cr    b  \cr  } } \right)}  \cdot {\left( {\matrix{   x  \cr    y  \cr  } } \right)^T}$$</p><p>3、方阵的逆？</p><blockquote><p>为何要求逆？<br>因为$$Ax = b,x = {A^{ - 1}}b$$，如果有很多b，可以复用${A^{ - 1}}$的结果，<code>减少计算量</code>；</p><p>如何求解${A^{ - 1}}$？</p></blockquote><p>原理：$$(A{\rm{|}}E) \sim (E{\rm{|}}{A^{ - 1}})$$<br>方法：通过高斯-约旦消元法进行初等变换，即可求出；</p><p>4、矩阵分解？</p><h3 align="center">$$A = LU$$</h3><ul><li>分解目的：加速求解线性方程组；</li><li><p>含义：$$A = LU$$，L：单位下三角矩阵，U：上三角；</p></li><li><p>求解方法：利用高斯消元法，有：$$(\prod {{E_i})}  \cdot A = U,A = LU$$，这里L如果凑巧的话为单位下三角；</p></li><li><p>时间复杂度：$$T = O({{{n^3}} \over 2})$$</p></li><li><p>求解线性方程组？<br>第一步：$A = LU$</p></li></ul><p>第二步：$LUx = b,Ly = b$先求出y，此时复杂度为$T = O({{{n^2}} \over 2})$;</p><p>（因为下三角且为1每行只需要操作1所在元素，其他全为0）；</p><p>第三步：再次求解$Ux = y $，利用转置（或者约旦消元）可以求得<br>$T = O({{{n^2}}})$</p><p>所以：<br>$$T = O({{{n^3}} \over 2}) + 2O({{{n^2}} \over 2})$$</p><p>然而初等变换求逆矩阵：$$T = O\{ [2n \times (n - 1) +  \cdots 2n \times 1] \times 2\}  = O(2{n^3})$$</p><h3 align="center">$$A = QR$$</h3><ul><li>含义：Q:标准正交矩阵；R（上三角矩阵）</li><li><p>用途：解方程组、PCA基础：</p>$Ax = b,QRx = b,Rx = {Q^T}b$<p>因为右边好求，R为三角阵也好求，所以简化线性方程组求解办法；</p></li><li><p>如何求解Q,R?<br>思想：求出Q然后反向求出R；</p>$A{\rm{ = }}Q \cdot R$$$R = {Q^T} \cdot A$$</li></ul><h3 align="center">$A = U\Sigma {V^T}$</h3><p>*辨析：奇异值是针对矩阵$A${% endraw %，特征值是针对矩阵{% raw%}${A^T}A${% endraw %}：</p><ul><li>含义：{% raw%}$${A_{m \times n}} = {U_{m \times m}}{\Sigma _{m \times n}}{V^T}_{n \times n}$${% endraw %}<br>① {% raw%}${{\rm{U}}_{m \times m}}${% endraw %}为标准正交阵；</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/正交.png" alt=""></p><p>② {% raw%}${V^T}${% endraw %}是{% raw%}${A^T}A${% endraw %}的特征向量进行标准化之后的矩阵（标准正交矩阵）；</p><p>③ Σ：奇异值矩阵：<br>{% raw%}$$\Sigma {\rm{ = }}\left( {\begin{array}{*{20}{c}}{{\sigma _1}}&amp;0&amp;0\\0&amp;{{\sigma _r}}&amp;0\\0&amp;0&amp;0\end{array}} \right)$${% endraw %}<br>其中：{% raw%}${\sigma _i} \ne 0,{\sigma _i} \ge {\sigma _{i + 1}}${% endraw %}：</p><ul><li>算法过程：</li></ul><p>S1:求解{% raw%}${A^T}A${% endraw %}特征值、特征向量；</p><p>S2:奇异值从大到小排序，得到{% raw%}$Σ${% endraw %}；<br>S3:特征向量标准化得到矩阵{% raw%}$V${% endraw %}；<br>S4:求出{% raw%}${u_i} = \frac{{A\overrightarrow {{\varepsilon _i}} }}{{{\sigma _i}}}${% endraw %}{% raw%}${\lambda _i}≠0${% endraw %}，然后施法拓展；</p><ul><li>SVD分解应用？</li></ul>{% raw%}$A = (U\Sigma ){V^T} = ({u_1}{\sigma _1}, \cdots ,{u_r}{\sigma _r},0){V^T} = \sum\limits_1^r {{u_i}{\sigma _i}{v_i}^T} ，{\sigma _i} \ge {\sigma _{i{\rm{ + }}1}}${% endraw %}<p>即：矩阵{% raw%}$A${% endraw %}可以看成多个<code>递降权值</code>的矩阵之和；常用于（图像）<strong>矩阵压缩</strong>、降噪、降维，保留大的奇异值的矩阵；</p><h2 align="center">向量空间</h2><p>1、向量空间？</p><blockquote><p>定义：向量的集合，此处<code>向量</code>为广义向量，<br>即满足：<code>向量:含有加法、数乘两种运算以及含封闭性的十种性质的一切对象</code>；</p><p>举例：欧氏空间{% raw%}${R^N}${% endraw %}、所有2x2矩阵、所有多项式；</p></blockquote><p>2、维度？</p><blockquote><p>向量<code>空间维度</code>指：该向量空间的极大无关向量的个数；<br><code>向量维度</code>指：该向量有几个数字构成（该点位于几维空间中）；</p></blockquote><h3 align="center">零空间</h3><p>1、定义：齐次线性方程组的解向量组成的向量空间；<br>2、含义：<br>① 0空间为所有向量被A矩阵变换到0向量的所有向量；<br>② 0空间中所有向量<strong>正交</strong>于A矩阵行向量；</p><h3 align="center">子空间</h3><p>1、定义：向量空间V的子集S并且S<strong>必须也是一个向量空间</strong>；<br>2、作用：降维；</p><h2 align="center">线性变换</h2><p>1、线性变换：{% raw%}$T(v)${% endraw %}<br>2、条件：<br>{% raw%}$$T(v + u) = T(v) + T(u);T(cv) = cT(v)$${% endraw %}<br>3、矩阵与线性变换：</p><blockquote><p>特别的：在欧几里得空间中，<strong>矩阵=线性变换=投影变换</strong>；</p><p>  此时：<br>{% raw%}$$T(\overrightarrow v ) = A \cdot \overrightarrow {(v)} $${% endraw %}</p></blockquote><p>4、举例：<br>{% raw%}$$A = \left( {\matrix{   0 &amp; 1  \cr    1 &amp; 0  \cr  } } \right)$${% endraw %}<br>表示翻转变化，关于y=x对称，此时特征向量为y=x上向量，对应特征值为1；</p><p>而y=-x上向量翻转后对应λ为-1的特征向量；</p><h2 align="center">相似变换</h2><p>1、{% raw%}$A = {P^{ - 1}} \wedge P${% endraw %}<br>2、含义：表示A变换在P坐标系下观察到的变换^；</p><p>3、应用：求方阵的幂；</p><h2 align="center">最小二乘法</h2><p>1、思想：线性方程组{% raw%}$Ax = b${% endraw %}实际中经常无解，所以采取<code>投影</code>，{% raw%}$b \to b' \in col(A)${% endraw %}，求出近似解；</p><p>2、此处<code>投影</code>即<code>最近</code>的数学描述；</p><h1 align="center">统计学部分</h1><p>1、统计思维？</p><blockquote><p>指：基于数据，用统计工具进行描述得到关于研究对象的规律，从而方便决策与预测；<br>简而言之：用数据说话，从数据获取对象特征；</p></blockquote><p>2、统计学分类？</p><blockquote><p>统计学包括<code>描述统计</code>、<code>统计推断</code>两大类，其中统计推断包括<code>参数估计</code>、<code>假设检验</code>两大部分，不过<code>频率派</code>和<code>贝叶斯学派</code>对这两部分计算方法有不同观点；</p></blockquote><p>如：<img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/假设检验.png" alt="频率派和贝叶斯学派假设检验"></p><p>3、统计学的处理方法？</p><blockquote><p>处理方法依数据类型决定，数据大体分为4类，无序分类变量、有序分类变量、等距数值变量、等比数值变量，各自有不同取值及其数字特征与图表描述方法；</p><p>数字特征：<br>集中趋势：众数、中位数、均值；<br>离散趋势：方差、极差、标准差；<br><strong>注意样本方差分母为n-1，总体方差分母为n</strong></p></blockquote><p>4、什么是概率，条件概率和积概率？</p><blockquote><p>频率派认为概率是事物发生可能性的客观描述，而<br>贝叶斯学派认为概率是每个人的主观经验和感受；</p><p>条件概率：{% raw%}$P(B{\rm{|}}A)${% endraw %}表示A已知（已经确定）条件下B发生的概率，其样本空间为A；</p></blockquote><p>积事件：{% raw%}$P(A \cdot B)${% endraw %}表示A,B同时发生（交集）的概率，其样本空间为S；</p><p>5、什么是大数定理、中心极限定理、切比雪夫不等式？</p><blockquote><p>大数定理：试验次数足够多，频率趋近概率这一稳定值；<br>随机试验大量独立重复最终呈现几乎必然的规律；</p><p>中心极限定理：大量随机变量之和标准化后服从正态分布；<br>即：二项分布极限分布为正态分布，如掷n次骰子，取点数之和为随机变量；</p><p>切比雪夫不等式：{% raw%}$P(\left| {X - u} \right| &lt; \varepsilon ) \ge 1 - {{{\sigma ^2}} \over {{\varepsilon ^2}}}${% endraw %}即：<code>至少有3/4的数据落在均值两个标准差范围内</code>；</p></blockquote><h2 align="center">统计推断</h2>1、流程：![统计推断流程](https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/统计推断.png)2、参数估计：频率派：`前提`：正态总体，分布已知，求出参数Θ；* 点估计：总体抽取样本构造统计量进行估计，用样本代替总体参数；&gt; 一般的，有矩法估计和极大似然估计；* 区间估计：目标就是估计出一个范围和可信程度；方法为寻找一个区间，使得其概率为1-α，&gt; 1-α表明该区间包含真值的可信度为1-α，即不妨设1-α为75%，表明1000次实验，750次该区间包含真正的参数Θ真值；3、假设检验：频率派：前提：正态总体，分布已知，参数未知，对0假设进行判断；检验方法：&gt; 第一步：写出原假设、备择假设；第二步：构造统计量（卡方、t、F）；第三步：采用P值检验法/临界值法求拒绝域；第四步：拒绝原假设或者不拒绝原假设！检验误差：&gt; 分为两类，第一类错误：弃真α；第二类错误：取伪β；4、假设检验推广之多个总体检验：前提：N个正态总体，{% raw%}${s_i} \sim N({u_i},{\sigma ^2})${% endraw %}，判断期均值是否全相等；检验方法：方差分析表；5、假设检验推广之`非参数方法`：前提：不要求总体分布为正态分布，总体分布未知；典型方法：{% raw%}$$bootstrap$${% endraw %}、秩和检验、符号秩检验；其中：秩{% raw%}$r${% endraw %}表示数据排序后的序号，重复的按照均值代替（结）；<h2 align="center">回归</h2><p>1、协方差与相关系数：刻画两个随机变量<code>线性关系</code>的<code>强度与方向</code>；</p>{% raw%}$$Cov(X,Y) = \frac{{\sum\limits_{i = 0}^N {\left( {{X_i} - \bar X} \right)} \left( {{Y_i} - \bar Y} \right)}}{{N - 1}}$${% endraw %}{% raw%}$$\rho  = \frac{{{\rm{cov}}(x,y)}}{{{S_x}{S_y}}}$${% endraw %}<p>2、相关与一元线性回归的区别：</p><p>线性回归可以预测而相关不可以；</p><p>3、一元线性回归：</p><ul><li>最佳拟合直线：</li></ul><p>前提：假设总体服从正态分布-{% raw%}${Y_i}\~\;N(a + bx,{\sigma ^2})${% endraw %}、自/因变量为线性关系（散点图法）；</p><p>求法：极大似然法求a,b:<br>{% raw%}$Y{\rm{ =  }}a + bx{\rm{ + }}\varepsilon ,\varepsilon \~N(0,{\sigma ^2})${% endraw %}</p><blockquote><p>如果不是正态总体，残差{% raw%}${\sum {({y_i} - \mathop y\limits^ \wedge  {\mkern 1mu} )} ^2}${% endraw %}平方和最小的思想即熟悉的<code>最小二乘法</code>；</p></blockquote><p>解法：求偏导，得到；<br>{% raw%}$$\mathop y\limits^ \wedge  {\mkern 1mu}  = {\beta _0}{\rm{ + }}{\beta _1}x$${% endraw %}</p><ul><li>评价标准:{% raw%}$$\mathop y\limits^ \wedge  {\mkern 1mu}  = {\beta _0}{\rm{ + }}{\beta _1}x$${% endraw %}</li></ul><p>① {% raw %}$RMSE：${% endraw %}残差和平方的均值开根号；</p><p>② {% raw %}${R^2}${% endraw %}=1-残差平方和/偏差平方和=模型解释的变化/总变化占比=相关系数的平方；</p><h2 align="center">贝叶斯推断</h2><p>1、大纲：</p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/贝叶斯推断.png" alt="贝叶斯推断"></p><p>2、贝叶斯推断：求出{% raw%}$P(Hi{\rm{|}}D)${% endraw %}中的最大值；</p><p><strong>从已有数据下推断其本质（某个假设的概率）</strong>，<br>如已经检测为核酸阳性推测是艾滋病的概率：<br>{% raw %}$$P({H_i}|{\rm{D}}) = {{P(D|{{\rm{H}}_i})P({H_i})} \over {\sum\nolimits_i {P(D|{{\rm{H}}_i})P({H_i})} }}$${% endraw %}</p><p>其中：{% raw %}$D${% endraw %}为数据，分母为边缘似然，{% raw %}${{H}_{i}}${% endraw %}为第{% raw %}$i${% endraw %}个假设，<br>{% raw%}$P(Hi)${% endraw %}表示先验概率，由观察者的主观经验决定；<br>{% raw%}$P(D{\rm{|}}Hi)${% endraw %}为似然概率；此时{% raw%}$P(Hi{\rm{|}}D)${% endraw %}为后验概率；<br>第二轮（如上图)，通过贝叶斯更新，把后验概率作为新一轮的先验概率，更新信念，使得先验更符合客观事实；</p><blockquote><p>这一点说明：后验概率是先验和似然的综合；<br>贝叶斯应用：垃圾邮件识别；</p></blockquote><h2 align="center">贝叶斯派与频率派之争</h2><p>1、参数估计：<br>频率派：未知参数是确定的，只是我们不知道（上帝视角）；<br>方法：MLE极大似然：<br>{% raw%}$$P(D{\rm{|}}Hi)$${% endraw %}出现概率最大；</p><p>贝叶斯学派：未知参数服从某个分布，先验概率通常取均匀分布；<br>方法：MAP最大后验概率；<br>{% raw%}$$P(Hi{\rm{|}}D)$${% endraw %}出现概率最大</p><h2 align="center">马尔科夫</h2><p>1、随机过程：随机变量（状态）随着时间变化的过程，按照时间为离散还是连续分为随机序列/连续参数随机过程；</p><p>2、马尔科夫性：将来的状态只与现在有关，与过去无关；</p><p>3、马尔科夫链：时间与状态取值都是离散的马尔科夫过程；</p><blockquote><p>数学形式：{% raw%}$$P\{ X({t_n}){\rm{|}}X({t_{n - 1}}){\rm{ = }}{x_{n - 1}},X({t_{n - 2}}){\rm{ = }}{x_{n - 2,}}X({t_1}){\rm{ = }}{x_1}\}  = P\{ X({t_n}){\rm{|}}X({t_{n - 1}}){\rm{ = }}{x_{n - 1}}\} $${% endraw %}</p></blockquote><p>4、转移概率：<br>{% raw%}$${P_{ij}}(m,m + n) = P({X_{m + n}}{\rm{ = }}{a_j}{\rm{|}}{X_m} = ai)$${% endraw %}</p><blockquote><p>特别的，各行之和为1（有且转移一个）；</p></blockquote><p>5、齐次马氏链：转移概率只与间隔n有关的马氏链；</p><p>6、一步转移概率：转移概率中n=1；</p><p>7、多步转移矩阵求解：{% raw%}$${P_n} = {P_1}^n$${% endraw %}正交标准化即可；</p><p>8、遍历性：</p><p>定义：n步转移矩阵的极限，每一列为π（j），暗含最终稳定状态；</p><p>9、马尔科夫链的应用：<br>压缩算法：如7-zip；语音识别；GOOGLE PR页面；</p><p>① <code>page rank</code>思想：</p><p>表示：每个网页用图节点表示，互相引用（含有超链接）表示有向箭头，一步转移矩阵按照列引用写出矩阵；</p><p>目的：求出遍历性，取值最高的π(j)（最后稳定情况下链接最多的页面）为质量最高的页面；</p><p>修正：由于遍历不能为0，进行修正：G’=αG+(1-α)U/n；U：全1矩阵；G-一步转移矩阵；<br>//α不仅满足遍历同时反映实际意义：在当前页面停留的概率；</p><h1 align="center">信息论部分</h1><p>1、信息熵：Σ-P(ai)*logP（ai）；<br>2、交叉熵：<br>衡量2个随机变量之间的相似度-交叉熵损失函数；<br>定义：H(P,q)=-Σp(i)log(q(i))<br>3、互信息：I（xi,yi）表示收到消息yi后关于xi的信息量=logP(Xi|Yi)/P(Xi)：<br>应用：用于筛选特征；<br>4、<code>KL</code>散度：相对熵：P（x）为随机变量Q(X)上的两个概率分布；<br>KL(P||Q)=ΣP(x)log[P(x)/Q(x)]<br>应用：衡量两个随机分布之间的距离，用于比较文本相似度，先统计出词频然后计算相对熵</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://zhujie-ww.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://zhujie-ww.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数学基础" scheme="https://zhujie-ww.github.io/tags/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的统计学</title>
    <link href="https://zhujie-ww.github.io/posts/1002/"/>
    <id>https://zhujie-ww.github.io/posts/1002/</id>
    <published>2020-04-16T09:48:07.990Z</published>
    <updated>2020-04-16T13:27:43.048Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 align="center">程序员的统计学</h1><p>1、什么是统计学？<br>统计学：基于数据得到客观现象的内在规律性从而做出决策与预测！</p><p>2、为什么学习统计学？<br>为了培养 <strong>统计思维</strong>：</p><blockquote><p>统计思维：用相对简单的特征来尽可能准确描述现实世界，并且允许对不确定性进行量化!</p></blockquote><p>举例：北京买房，预算200万，如何分析是否够？<br>方法：获得所有商品房价格，而后进行计算；<br>（抽样）——(数字特征)———-置信区间——————————-<br>例：抽烟活100岁——抽烟好！—-个例；</p><blockquote><p>人是非理性的，信息获取有偏差，直觉，幸存者偏差；</p></blockquote><p>3、统计学有哪些分类？<br>描述统计、统计推断（频率派：参数估计、假设检验、贝叶斯派：贝叶斯统计）</p><p> <img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/统计学大纲.png" alt="统计学分支"> </p><p> <img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/假设检验.png" alt="频率派和贝叶斯学派假设检验"></p><p>4、统计学与机器学习对比：<br>统计学注重可解释性：本质与机制，追求为什么；<br>机器学习注重应用：追求准确率，不关注黑盒内部如何实现，给出是什么；</p><p>5、统计学研究数据，有哪些数据呢？<br>数据分类：（不同数据有不同操作集和统计方法）：</p><ul><li>每个数字都有独特含义（名目尺度）（定性/无序分类变量）<br>如：<code>性别</code>、<code>颜色</code>；</li><li>数字有序（次序尺度，含①特点）（定性/有序分类变量）<br>如：<code>教育程度</code>、<code>评价</code>；</li><li>任何位置单位间距相同（等距尺度）（定量/数值变量）<br>如：<code>年份</code>、<code>温度</code>；</li><li>不存在0值（等比尺度）（定量/数值变量）<br>如：<code>身高</code>、<code>体重</code>、<code>年龄</code>；</li></ul><h1 align="center">描述统计</h1><p>1、大纲：</p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/描述统计.png" alt="描述统计"></p><p>2、如何判断数据是否可靠与有效？</p><blockquote><p>可靠性：多次测量的到的数据是否一致；</p><p>有效性：实际测量对象=目的对象；</p></blockquote><p>3、各变量数字特征与图表：</p><ul><li>无序分类变量：如<code>性别</code>：<br>图表：频率表、条形图；<br>  数字特征：众数；</li><li>有序分类变量：如<code>教育程度</code>：<br>图表：频率表、条形图；<br>  数字特征：众数，中位数；</li><li>数值变量：<br>图表：频率直方图；箱线图；<br>数字特征：<br>集中趋势：众数、中位数、均值；<br>离散趋势：极差、分位数[2分位、四分位]、方差</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/箱线图.png" alt="箱线图"></p><blockquote><p>P.S:四分位计算方法：先找二分位线，左右两边再找二分位线（递归查找中位数）；</p></blockquote><ul><li>数值变量：等比变量：如花瓣长度：<br>  图表：箱线图、频率直方图；<br>数字特征：方差、标准差；</li></ul><p>4、极端值与缺失值：<br>极端值定义：小于Q1-3IQR,大于Q3+33IQR的值；<br>    来源：数据来自不同总体、小概率事件发生了、测量/记录/输入错误；<br>极端值影响：<br><code>特别影响均值、极差、方差，不太影响中位数、众数、IQR；</code></p><p>如何处理：测量失误—丢掉；其他情况，具体处理；<br>缺失值：1000个丢10个，那么没啥关系丢弃；其他情况：能否补全；</p><p>5、两个变量之间的关系：</p><ul><li>两个分类变量的关系：<br>遇难船只的325名乘客：幸存与否、年龄（儿童/成人）<br>构建原始数据表；年龄与幸存是否有关系？<br>关联表；有关不等于因果关系！<br>分段条形图；相对频率分段条形图</li></ul><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/关联表.png" alt="关联表"></p><ul><li>两个数值变量关系：工资与入职时间关系：散点图；</li><li>数值与分类变量关系：工资与性别；房价与学区房；并排箱图；</li></ul><h1 align="center">概率论</h1><p>1、什么是概率：<br>频率派认为概率是频率的极限；<br>贝叶斯学派认为是人的主观观念；</p><p>2、概率密度图像可以看成是频率分布直方图的极限；</p><p>3、大数定律：样本容量/试验次数足够多时，频率稳定趋向于概率；</p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/大数定律.png" alt="抛1000次硬币正面朝上概率"></p><h1 align="center">统计推断</h1><p>1、总体思路：总体中抽取样本进行参数估计，用假设检验衡量参数是否估计得合理；</p><blockquote><p>要求：总体分布已知、参数未知；</p></blockquote><p>2、大纲：</p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/统计推断.png" alt="统计推断流程"></p><p>3、中心极限定理：</p><blockquote><p>大量独立随机变量之和标准化后近似服从正态分布；</p></blockquote><p>实际中只需要样本容量大于30个就可以满足；</p><h1 align="center">参数估计</h1><p>1、参数估计：</p><ul><li>点估计：总体抽取样本构造统计量进行估计，用样本代替总体参数；<br>均值与期望：前者是基于样本，后者是上帝视角，基于总体的均值，后者为前者极限；</li><li>区间估计：估计出一个范围和可信程度；<br>置信水平为1-α的置信区间并不唯一，但是正态总体对称长度最小，精度最高；<br>1-α表明该区间包含真值的可信度为1-α；</li></ul><h1 align="center">假设检验</h1><p>1、前提：<br>总分分布只知道部分参数，提出关于总体的假设，根据样本决定接受还是拒绝假设，<br>我们不知道这一决策是否正确，但是知道决策犯错的频率；<br>2、假设：原假设（总体参数假设有等号）、备择假设；<br>3、检验：</p><blockquote><p>p值检验法：<br>P （样本观测值|原假设发生条件下）<br>若：P&gt;α，接受原假设，反之拒绝；</p></blockquote><p>4、假设检验之决策错误：<br>第一类错误：α（拒绝域）-弃真；<br>第二类错误：取伪-β；</p><blockquote><p>二者相互制约，通常考虑到错误后果严重性，控制第一类错误是选取较低的α水平；</p></blockquote><p>其中β由真值、样本容量决定；<br>5、假设检验之效应量（实际显著）：A班和B班平均分数为90,89.5，那么差距如何衡量？<br>Cohen’s D效应公示：d=X1罢-X2罢/S；0.2较小，0.5中等，0.8较大差距；</p><p>6、假设检验推广：ANOVA方差分析检验：</p><ul><li>t检验与ANOVA的区别：<br>t检验两个总体均值；方差分析多组H0=全等，H补全等；<br>如用A,B,C教学方法（教学方法为自变量/因素）（该因素有三个水平，A,B,C）（单因素方差分析），分别对应学生成绩（因变量），假设U2=U3=U1表示教学方法对成绩无关，此为单因素方差分析；</li></ul><p>7、假设检验推广之<code>非参数方法</code>：</p><ul><li><p>非参数方法：</p><blockquote><p>总体分布未知/总体参数无限个，这时要对总体某些性质进行估计/假设检验；  </p></blockquote></li><li><p>非参数方法特点：<br>利用样本估计/检验总体性质中，不依赖于总体分布，统计量通常与总体分布无关；<br>优点：对数据要求不严格、较好的稳健性、不受总体分布限制；<br>缺点：如果符合参数方法的数据用非参数方法，第二类错误概率大；</p></li><li>什么时候使用非参数？</li><li>中位数而不是均值可以更好描述数据的集中趋势；</li><li>处理对象有极端值、是有序变量；</li><li>如果符合参数方法的数据次选用非参数方法；</li><li>样本不典型任何方法都错误；</li><li>举例：威尔森符号秩检验、威尔森秩和检验、皮尔曼相关检验；</li><li>bootstrp方法：总体分布未知，已有n个样本，现在从n中放回抽样n个得到的样本，独立重复k（一般大于1000次）次，即k次抽样，形成bootstap非参数方法；<br>如判断男女是否睡眠时间相同，采取中位数差值；</li></ul><h1 align="center">回归</h1><p>1、线性回归：</p><ul><li>协方差：两个数值变量共同变化程度； </li></ul>$$Cov(X,Y) = \frac{{\sum\limits_{i = 0}^N {\left( {{X_i} - \bar X} \right)} \left( {{Y_i} - \bar Y} \right)}}{{N - 1}}$$<ul><li>相关系数：</li></ul>$$\rho  = \frac{{{\rm{cov}}(x,y)}}{{{S_x}{S_y}}}$$<p>相关系数显示两个变量线性关系强度、方向；<br>r=-1到1；r绝对值表示线性关系的强弱；<br>r没有单位，不受平移伸缩影响，代表线性关系的强度与方向；<br>r受极端值影响大，r=0表示无线性关系；</p><p>2、一元线性回归：</p><ul><li>相关与一元线性回归的区别特点：<br>后者有自变量与因变量；可以给定自变量的值预测因变量；</li><li>最佳拟合直线：<br>数学思想：围绕回归直线均匀波动，一般情况是利用极大似然估计参数，假设:</li></ul>$$Y \sim \;N(a + bx,{\sigma ^2})$$$$Y \sim a + bx{\rm{ + }}\varepsilon ,\varepsilon {\rm{ }} \sim N(0,{\sigma ^2})$$<p> 特别的如果Y不是正态分布，那么即:</p><blockquote><p>最小二乘法，<br>使残差${\sum {({y_i} - \mathop y\limits^ \wedge  {\mkern 1mu} )} ^2}$平方和最小；</p></blockquote><p>求法：求偏导得到正规方程组，解出估计值；<br>$$\mathop y\limits^ \wedge  {\mkern 1mu}  = {\beta _0}{\rm{ + }}{\beta _1}x$$</p><p>此回归直线一定经过均值点；</p><ul><li>假设检验：如何判断这个线性假设正确呢？<br>对已有的点估计${\beta _1}$<br>进行（反应线性相关程度）假设检验看其是否为0（是否有实际价值）；</li><li>一元线性回归前提条件：</li><li>自变量因变量是线性关系，可以用散点图、残差图检验；</li><li>残差服从标准正态分布，可以用频率直方图检验；</li><li>残差围绕y=0变化程度基本不变（围绕y=0上下波动程度差不多—振幅近似）；</li><li>回归模型的评价标准:$$\mathop y\limits^ \wedge  {\mkern 1mu}  = {\beta _0}{\rm{ + }}{\beta _1}x$$</li></ul>$RMSE$残差和平方的均值开根号；${R^2}$=1-残差平方和/偏差平方和=模型解释的变化/总变化占比=相关系数的平方；//假设检验统计量的分母：自由度=样本容量-模型未知参数个数；3、多元线性回归之共线性：两个自变量相关，成为共线；意义：自变量本应独立，剔除共线向量；简约性（奥卡姆剃刀）：同一个问题多种理论都可以准确预测，那么选择假设最少的；4、机器学习中的回归和统计中的回归：同：求解函数、求解方法、评价指标:$$RMSE,{R^2},{R^2}_{adjust}$$<p>不同：<br><code>统计学</code>：注重可解释性，聚焦当前数据，挖掘出本质和机制；前提条件；假设检验（对做出的决策进行控制）；考虑影响模型准确性的因素；<br><code>机器学习</code>：注重应用性，预测；不会假设检验，不考虑模型估计准确性因素（此二者为特征工程的范畴）；</p><p>5、回归与各种检验的关系：<br>各种检验都是回归的特殊形式；</p><p></p><h1 align="center">贝叶斯统计</h1><br>1、大纲：<p></p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/贝叶斯推断.png" alt="贝叶斯推断"></p><p>2、贝叶斯公式：<br>得到数据情况下推测假设成立的概率；<br>概率树：辅助计算贝叶斯后验概率：</p><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/概率树.png" alt="概率树"></p><p>3、贝叶斯推断：<br>从已有数据下推断其本质（某个假设的概率），<br>如已经检测为核酸阳性推测是艾滋病的概率：<br>$$P({H_i}|{\rm{D}}) = {{P(D|{{\rm{H}}_i})P({H_i})} \over {\sum\nolimits_i {P(D|{{\rm{H}}_i})P({H_i})} }}$$</p><p>其中：$D$为数据，分母为边缘似然，${{H}_{i}}$为第$i$个假设，<br>P（Hi）表示先验概率，由观察者的主观经验决定；P（D|Hi）为似然概率；<br>此时P（Hi|D）为后验概率；第二轮，通过贝叶斯更新，把后验概率作为新一轮的先验概率，更新信念；<br>艾滋病事例中97,3开，这个时候需要考虑其他因素；</p><p><code>贝叶斯因子</code>：P（D|H1）/P（D|H2）衡量数据更支持那一个模型；<br>如果贝叶斯因子&lt;1表示支持H2；&gt;100极其支持H1；</p><blockquote><p>odds，odds ratio：<br>odd of hiv=P（HIV）/P(NO HIV)<br>odds ratio：后验比值/先验比值；</p></blockquote><p>4、先验概率对后验概率的影响：</p><blockquote><p>后验概率是先验概率和似然函数的综合；</p></blockquote><p>所以先验概率选择很重要，后续通过迭代收敛至可靠值；</p><p>样本容量对于后验概率的影响：大样本降低了不确定性，更为精确；</p><p>5、置信区间；拒绝采样方法求得很多个数，排成一排，横坐标为后验概率，纵坐标堆积点；95%置信区间表示真值落在该区间的概率（个数）；</p><p>——一种办法95%，5%，两边非别为2.5%个个数，即可；</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="统计学" scheme="https://zhujie-ww.github.io/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="https://zhujie-ww.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Markdown语法学习</title>
    <link href="https://zhujie-ww.github.io/posts/1001/"/>
    <id>https://zhujie-ww.github.io/posts/1001/</id>
    <published>2020-04-12T02:01:31.589Z</published>
    <updated>2020-04-12T03:30:58.308Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 align="center">Markdown笔记</h1><h1 id="0-字体设置："><a href="#0-字体设置：" class="headerlink" title="0-字体设置："></a>0-字体设置：</h1><blockquote><p><code>&lt;font face="方正楷体"&gt;这是方正楷体&lt;/font&gt;</code></p><font face="方正楷体">这是方正楷体</font></blockquote><h1 id="1-标题："><a href="#1-标题：" class="headerlink" title="1-标题："></a>1-标题：</h1><blockquote><p><code># 一级标题</code></p><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><blockquote><p><code>## 二级标题</code></p><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2></blockquote></blockquote><ul><li>注意空格</li><li>至多6级；</li></ul><h1 id="2-标记："><a href="#2-标记：" class="headerlink" title="2-标记："></a>2-标记：</h1><blockquote><p><code>\**这是加粗文本**</code></p></blockquote><p><strong>这是加粗文本</strong></p><blockquote><p><code>*这是斜体文本*</code></p></blockquote><p><em>这是斜体文本</em></p><blockquote><p><code>**正文*斜体加粗* 正文**</code></p></blockquote><p><strong>正文<em>斜体加粗</em> 正文</strong></p><blockquote><p><code>~~删除线~~</code><br><del>删除线</del></p></blockquote><h1 id="3-引用："><a href="#3-引用：" class="headerlink" title="3-引用："></a>3-引用：</h1><ul><li>引用：<blockquote><p><code>&gt;**这一块是引用的**</code><br><strong>这一块是引用的</strong></p></blockquote></li></ul><ul><li>引用代码：<br>(单独引用)<blockquote><p>use `git here` command<br>use <code>git here</code> command</p></blockquote></li><li>引用代码块：</li></ul><blockquote><p>`<br>hexo clean<br>hexo g<br>hexo d<br>`</p></blockquote><pre><code>hexo cleanhexo ghexo d</code></pre><p>* 一行代码：    </p><blockquote><p>四个空格即可：</p></blockquote><pre><code>1234</code></pre><ul><li>多重引用：<blockquote><p>&gt;P1<br>&gt;&gt;P2<br>&gt;&gt;&gt;P3</p></blockquote></li></ul><blockquote><p>P1</p><blockquote><p>P2</p><blockquote><p>P3</p></blockquote></blockquote></blockquote><ul><li>语法高亮：<blockquote><p>```c<br>int main(){<br>printf(“hello,world\n”);<br>return 0;<br>}<br>```</p></blockquote></li></ul><pre class=" language-lang-c"><code class="language-lang-c">int main(){printf("hello,world\n");return 0;}</code></pre><h1 id="4-超链接："><a href="#4-超链接：" class="headerlink" title="4-超链接："></a>4-超链接：</h1><blockquote><p>[谷歌](www.google.com “这是链接标题,鼠标经过显示内容”)</p></blockquote><ul><li><a href="www.google.com" title="这是链接标题,鼠标经过显示内容">谷歌</a>            </li></ul><blockquote><p><code>&lt;http:www.baidu.com&gt;</code></p></blockquote><ul><li><a href="http:www.baidu.com" title="这是百度">URL链接</a></li></ul><blockquote><p><code>![saber](https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/friendslink.jpg "哈哈哈")</code></p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/friendslink.jpg" alt="saber" title="哈哈哈"></p><h1 id="5-无序列表（-）"><a href="#5-无序列表（-）" class="headerlink" title="5-无序列表（+-*）"></a>5-无序列表（+-*）</h1><pre><code>- HH- CC- FFS- SDF+ RRR</code></pre><ul><li>HH</li><li>CC</li><li>FFS</li><li>SDF</li></ul><ul><li>RRR</li></ul><h1 id="6、有序列表："><a href="#6、有序列表：" class="headerlink" title="6、有序列表："></a>6、有序列表：</h1><pre><code>1. 222. 343. 4344. 345. 44</code></pre><ol><li>22</li><li>34</li><li>434</li><li>34</li><li>44</li></ol><h1 id="7-列表分级："><a href="#7-列表分级：" class="headerlink" title="7-列表分级："></a>7-列表分级：</h1><pre><code>- 第一             - 第二                         - 第三</code></pre><ul><li>第一         <ul><li>第二                <ul><li>第三</li></ul></li></ul></li></ul><p>(前后多次加多个空格！)</p><h1 id="8-任务列表"><a href="#8-任务列表" class="headerlink" title="8-任务列表"></a>8-任务列表</h1><pre><code>- [ ] 学习毛泽东思想- [x] \(Optional) Open a followup issue</code></pre><ul><li>[ ] 学习毛泽东思想</li><li>[x] (Optional) Open a followup issue</li></ul><h1 id="9-表情"><a href="#9-表情" class="headerlink" title="9-表情"></a>9-表情</h1><pre><code>:kissing::joy:</code></pre><p>:kissing:<br>:joy:</p><h1 id="10-转义字符："><a href="#10-转义字符：" class="headerlink" title="10-转义字符："></a>10-转义字符：</h1><pre><code>\</code></pre><p><code>\</code></p><h1 id="11-图片引用："><a href="#11-图片引用：" class="headerlink" title="11-图片引用："></a>11-图片引用：</h1><ul><li>绝对路径</li><li>相对路径：<br>  <code>![](/medias/1.jpg)</code><br>  //同级；<br> <code>![](/medias/1.jpg)</code><br>  //下一级；<h1 id="12-下划线："><a href="#12-下划线：" class="headerlink" title="12-下划线："></a>12-下划线：</h1></li></ul><p><code>_ _ _</code></p><hr><h1 id="13-表格："><a href="#13-表格：" class="headerlink" title="13-表格："></a>13-表格：</h1><pre><code>|姓名 | 性别 |工资 |工龄|职位|---|:--:|---|----|-||张三|男|2000|2|经理| 默认左对齐|</code></pre><div class="table-container"><table><thead><tr><th>姓名</th><th style="text-align:center">性别</th><th>工资</th><th>工龄</th><th>职位</th></tr></thead><tbody><tr><td>张三</td><td style="text-align:center">男</td><td>2000</td><td>2</td><td>经理</td></tr><tr><td>默认左对齐</td></tr></tbody></table></div><h1 id="14-排版："><a href="#14-排版：" class="headerlink" title="14-排版："></a>14-排版：</h1><ul><li>回车：两个回车才是回车，一个=回车空格符号；</li><li>缩进：<ul><li>一个英文：<br> 缩进一格；<ul><li>一个中文：<br> 缩进2格；</li><li>中文1/4位：<br>&nbsp;缩进1/4</li></ul></li></ul></li></ul><pre><code>缩进0格&amp;nbsp;缩进1/4个中文字符；&amp;ensp;缩进一格；&amp;emsp;缩进2格（一个中文字符)；</code></pre><ul><li>居中：</li></ul><pre><code>&lt;div align=center&gt;哈哈&lt;/div&gt;</code></pre><div align="center">哈哈</div><h1 id="15-脚注："><a href="#15-脚注：" class="headerlink" title="15-脚注："></a>15-脚注：</h1><pre><code>解释文本[^er][^er]:111</code></pre><p>解释文本<sup><a href="#fn_er" id="reffn_er">er</a></sup></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="Markdown" scheme="https://zhujie-ww.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>慕课网线性代数</title>
    <link href="https://zhujie-ww.github.io/posts/1000/"/>
    <id>https://zhujie-ww.github.io/posts/1000/</id>
    <published>2020-04-06T03:11:31.666Z</published>
    <updated>2020-04-16T16:01:12.320Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 align="center">概述</h1><p>1、线性代数研究一组数，即向量，<br>  以及向量的“函数”-矩阵；</p><blockquote><p>一组数更能真实模拟与描述我们的三维世界，单变量函数不精确；</p></blockquote><p>2、机器学习学习方法：<br>     不一定要学透数学再学机器学习，</p><blockquote><p>可以先实战、先入门然后有目的的补数学，带着目标学习；</p></blockquote><p>3、机器学习需要：<br>高数、线代、统计学（最重要）、凸优化</p><p>4、花书：深度学习圣经：</p><p>         <a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener">花书链接</a></p><p>4、一手资源几乎全是英语，建议平时加强英语学习；</p><h1 align="center">向量</h1><p>1、向量：</p><p>① 起源：表示方向的有向线段，物理中速度、加速度；</p><p>② 与起点无关，默认从0,0开始；</p><p>③ 向量=点/有向线段；</p><p>④ 分类；行、列向量；</p><p>⑤ 向量加法：先走a在走b等价于先走b后走a；</p><p>//向量（5,2）先向x方向走5步再向y方向走2步；</p><p>⑥ 计算机科学常用证明方法：反证法、归纳法；</p><p>⑦ 向量内积：三角形借助余弦定理求出,定义为内积;</p><p>// 内积几何意义：投影</p><p>⑧ 点乘的应用：判断两个向量的相似程度（推荐系统）：</p><p>//推荐相似的物品，每一个物品都是高位空间的点（电影价格、导演、评分、主演）</p><p>每两个电影有夹角，锐角—-相似；垂直：无关；<br>如果点乘越大的正数：考虑完全重合情形；</p><h1 align="center">矩阵</h1><p>1、矩阵的几种理解：</p><p>① 矩阵=数表，工资表;</p><p>② 矩阵=线性系统（线性方程组），</p><p>如经济系统，网络中交通网络、信息网络，电路系统中电阻等式；化学系统中等式问题；</p><p>③ 矩阵乘法：行点乘，列组合；</p><p>④ 矩阵乘法：相当于向量的函数；</p><p>⑤ 矩阵=线性空间</p><p>列向量-第一列=基坐标1，第二列=基坐标2，张成新空间；</p><p>//表示新的空间中点的新坐标；</p><p>⑥ 矩阵=线性变换—恒纵坐标拉伸旋转变换；</p><p>可以直接写出翻转旋转的空间坐标（不能表示平移变换，因此引入仿射变换概念）；</p><p>⑦ 初等矩阵=初等变换；</p><p>2、求解矩阵的逆：</p><p>方法：(A|E)初等行变换，</p><p><strong>电算步骤：</strong></p><blockquote><p>高斯（从上到下）-约旦（从下至上）方法；</p><p>本质：高斯-约旦消元法等价于找到一系列初等矩阵使得：<br>$${E_1}{E_2} \ldots {E_k} = A$ $<br>所以：求逆矩阵=求逆变换；</p></blockquote><p>3、矩阵的逆重要性：</p><p>假设A可逆直接求出,那么此时当A不变，b有很多个时，此时可以复用,<code>减少计算量</code>；</p><p>4、矩阵的分解: <strong>LU分解</strong></p><p>① 分解目的：提高计算效率；</p><p>② 含义： L：单位下三角-主对角线为1；U：上三角；</p><p>③方法：高斯消元；</p><blockquote><p>高斯消元本质：</p><blockquote><p>初等变换为一个上三角矩阵；</p></blockquote></blockquote><p>④时间复杂度：$T = O(\frac{{{n^3}}}{2})$</p><p>(即求解L矩阵的次数)</p><p>证明：<br>左下方：<br>第一列下n-1个数字，每个数字需要操作n个数字（一行所有元素都要变化）<br>所以：<br>$$\sum\limits_{i = 1}^{n - 1} {i = {{n(n - 1)} \over 2}} $$</p><p>⑤ 作用：求解线性方程组：</p><p>第一步：$A = LU$</p><p>第二步：LUx=b,Ly=b先求出y，此时复杂度为$T = O({{{n^2}} \over 2})$;</p><p>（因为下三角且为1每行只需要操作1所在元素，其他全为0）；</p><p>第三步：再次求解Ux=y，利用转置（或者约旦消元）可以求得<br>$T = O({{{n^2}}})$</p><p>所以：<br>$T = O({{{n^3}} \over 2}) + 2O({{{n^2}} \over 2})$</p><p>⑥ 与求解逆矩阵求解AX=b的对比：</p><p>求解逆矩阵：利用初等变换：为：</p>$$T = O\{ [2n \times (n - 1) +  \cdots 2n \times 1] \times 2\}  = O(2{n^3})$$<p>所以LU分解性能极大增强；</p><h1 align="center">向量空间</h1><p>1、空间=一个集合；</p><p>2、特殊的向量空间：</p><p>欧几里得空间${R^N}$：有序实数元祖的集合（点集集合），n维空间的点；</p><p>如 $\left( {\begin{array}{*{20}{c}}5\\{66}\end{array}} \right)$</p><p>3、向量空间：<br>3.1  直观理解：元素为”向量”的集合(空间)；</p><p>3.2 什么是向量：不只是欧几里得中的有向点，还包括其他；</p><p>3.3  向量定义：</p><p>对于向量，我们定义两种运算：</p><blockquote><p>加法与数量乘法：</p></blockquote><p>同时还需要满足十条性质：</p><p>① <code>封闭性</code>：ku+v属于向量空间V（满足加法和数乘封闭）；</p><p>//例如整数对于加法封闭，除法不封闭；</p><p>② 交换律、结合律、存在0向量属于向量空间；</p><p>③ 其他可由以上两条推出！</p><p>3.4 什么是向量空间：同3.3：</p><p>欧几里得空间+其他空间；</p><p>广义向量空间：<br>{所有2*2方阵，所有m*n矩阵}；</p><blockquote><p>  所有多项式构成向量空间；所有某类函数构成向量空间}；</p></blockquote><p>反例:</p><p>//所有这种矩阵<br> $$\left( {\matrix{   1 &amp; a  \cr    0 &amp; 1  \cr  } } \right)$$<br> 不组成向量空间；</p><p>4、维度：<br>一个空间的极大无关组（基）的向量的个数；</p><p>—&gt;&gt;元素有几个数字，个数就是维度（错误:应当是极大无关组,注意区分向量维度和空间维度）；</p><p><code>特别的三维空间的过原点的平面，定义其维度为2；</code></p><p>5、行列视角：<br> $$\left( {\matrix{   {{a_{11}}} &amp;  \ldots  &amp; {{a_{1n}}}  \cr     \vdots  &amp;  \ddots  &amp;  \vdots   \cr    {{a_{m1}}} &amp;  \cdots  &amp; {{a_{mn}}}  \cr  } } \right)$$</p><p>① 行空间为n维空间的子集；列空间为m维空间的子集；</p><p>② 求法：高斯行变换为最简形的非0行数=行秩=行空间的维度；</p><p>③ 秩为矩阵的秩，维度为向量空间的维度；</p><p>④ 同理列空间的极大无关组一般通过初等行变换得到RREF型求解；</p><blockquote><p>  列空间的基(极大无关组)为化简后对应的原来的矩阵的列；</p></blockquote><p>⑤ 区分向量空间的维度和向量的维度；</p><p>⑥ Ra行=Rb列；所以行空间与列空间的维度相等；</p><p>6、零空间：</p><p>① 定义：齐次线性方程组的所有解向量形成一个向量空间，称为0空间；</p><p>矩阵A的零空间就是AX=0中所有x组成的空间；</p><p>② 深入理解0空间：</p><blockquote><p>  view1：A=函数变换：所有向量在矩阵A变换下映射到零点；</p><p>view2：A=系统：Ax=0所有解组成的空间；</p><p>view3：A=空间：零空间是一个集合，</p><blockquote><p>其中所有向量与A行向量点乘为0,A的0空间正交于A的行空间；</p></blockquote></blockquote><p>③ 空间正交：<br>任意两个向量垂直；如直线垂直平面，但是平面垂直平面不行（公共线不垂直）</p><p>—-两个二维平面（空间）在三维空间不正交，在4维正交；</p><p>④ 0空间的维度？<br>$n - r(A)$<br>:原因：非自由列有$r(A)$个，剩下的为自由列，也就是解的列空间个数；</p><p>秩+零化度（0空间的维度）=n</p><p>7、子空间：</p><p>① 定义：向量空间V的子集S并且<code>要求S还是一个向量空间</code>；</p><p>或者：S为V空间：S为向量空间V子集同时对加法、数乘封闭；</p><p>如平面xoy上过原点的直线（不能是射线）为其子空间，不过原点就不是子空间（不包含0向量）；</p><p>② 举例：</p><p>如三维空间，原点，过原点直线，过原点平面都是子空间；</p><p>--推而广之n为空间；</p><p>③ 子空间关系：</p><p>列空间：<br>$$col(A)\;\;\;\;\;\;\;\;\;\;r = a;$$<br>行空间：<br>$$col({A^T})\;\;\;\;\;\;\;\;\;\;r = a;$$<br>右0空间：<br>$$null(A)\;\;\;\;\;\;r = n - r(A)$$<br>//正交于行空间；</p><p>左0空间：<br>$$null(A)\;\;\;\;\;\;r = n - r(A^T)$$<br>//正交于列空间；</p><p>④ 子空间作用：  <code>降维</code>：</p><blockquote><p>AX=b，方程组个数太多（采集很多样本）很容易无解；</p><blockquote><p>于是对于Ax（表示矩阵A的列（向量组成的）空间）再取求解离A列空间离b最近的b’,求解Ax=b’;</p></blockquote></blockquote><p>//这就是<code>最小二乘法</code>的思路！</p><h1 align="center">施密特正交化</h1><p>1、二维情形：</p><p>问题：</p><p>已知u，v求垂直于u的向量</p><p>解法：</p><p>v垂直于u的投影向量可以求出为p，那么v-p向量必然垂直于u</p><p>所以：<br>$$\overrightarrow u ,\overrightarrow v  - {{\overrightarrow u  \cdot \overrightarrow v } \over {\left\| {\overrightarrow u } \right\|}} \cdot {{\overrightarrow u } \over {\left\| {\overrightarrow u } \right\|}}$$</p><p>就是所求的垂直向量；</p><p>2、三维：</p><p>a,b,c：任选两个a,b—u,v施法正交，第三个c投影到二维平面(uov)求第三个基，为方便求解，根据立体几何知识只需要在c投影到u,v二轴，求出投影向量k，然后c-k=w即可；</p><h1 align="center">分解</h1><p>1、矩阵QR分解：<br>$A = QR$<br>① 含义：Q:标准正交矩阵；R（上三角矩阵）</p><p>② 用途：解方程组：<br>$Ax = b,QRx = b,Rx = {Q^T}b$<br>因为右边好求，R为三角阵也好求，所以简化线性方程组求解办法；</p><p>③ 如何求解Q,R?</p><p>方法1：求法：借助<code>施法正交</code>等式，求出<br>${a_i}，{b_i}$的关系；</p>$$A = \left( {{a_1},{a_2}, \ldots ,{a_n}} \right)$$施法正交为(p1,p2,pn),规范化为(q1,q2,qn)那么：$\left\| {{p_1}} \right\|\overrightarrow {{q_1}}  = \overrightarrow {{p_1}}  = {a_1} \Rightarrow {a_1} = {r_{11}}{p_1}$$\left\| {{p_2}} \right\|\overrightarrow {{q_2}}  = \overrightarrow {{p_2}}  = {a_2} - {{{a_2} \cdot {p_1}} \over {{p_1}^2}} \cdot {p_1} \Rightarrow {a_2} = {r_{21}}{q_1} + {r_{22}}{q_2}$<p>所以：<br>$A = Q \cdot \left( {\matrix{   {{r_{11}}} &amp; {{r_{21}}} &amp; {{r_{31}}}  \cr    0 &amp; {{r_{22}}} &amp; {{r_{32}}}  \cr    0 &amp; 0 &amp; {{r_{33}}}  \cr  } } \right)$<br>方法2：实际使用的最多还是：<br>$A{\rm{ = }}Q \cdot R$<br>$$R = {Q^T} \cdot A$$</p><h1 align="center">基、坐标变换</h1><p>1、点的坐标以一组基为标准，<br> $\left( {\matrix{   x  \cr    y  \cr  } } \right) = \left( {\matrix{   1 &amp; 0  \cr    0 &amp; 1  \cr  } } \right) \cdot \left( {\matrix{   x  \cr    y  \cr  } } \right) = x \cdot \left( {\matrix{   1  \cr    0  \cr  } } \right) + y \cdot \left( {\matrix{   0  \cr    1  \cr  } } \right)$</p><p>坐标的值为对应基的线性组合的系数；</p><p>2、标准基:</p><p>含义：<br>$\left( {{e_1},{e_2},{e_3} \cdots {e_n}} \right)$<br>即:标准坐标系；</p><p>3、标准正交基和标准基；</p><p>前者为单位正交向量组，后者特指标准坐标系的基向量；</p><p>4、坐标系转换：</p><p>桥梁：${P_a} \cdot {x_a} = {P_b} \cdot {x_b}$，<br>${P_b}^{ - 1} \cdot {P_a} \cdot {x_a} = {x_b} &gt;  &gt;  &gt; {P_{a -  &gt; b}} \cdot {x_a} = {x_b}$（直观理解：条条大路走到该点）；</p><p>举例：<br>$$\left( {\matrix{   1 &amp; 0  \cr    0 &amp; 1  \cr  } } \right) \cdot \left( {\matrix{   3  \cr    9  \cr  } } \right) = \left( {\matrix{   1 &amp; 1  \cr    4 &amp; 1  \cr  } } \right) \cdot \left( {\matrix{   2  \cr    1  \cr  } } \right) = \left( {\matrix{   3  \cr    9  \cr  } } \right) = \overrightarrow v $$</p><h1 align="center">线性变换</h1><p>1、线性变换：$T(v)$<br>条件：<br>$$T(v + u) = T(v) + T(u);T(cv) = cT(v)$$</p><blockquote><p>特别的：在欧几里得空间中，矩阵=线性变换；</p><p>  此时：<br>$$T(\overrightarrow v ) = A \cdot \overrightarrow {(v)} $$<br>2、不同维度空间的变化：<br>3D到2D动画；计算机视觉：2D-&gt;3D；</p></blockquote><p>同维度：数据压缩—-新的基中y方向差别很小，降维为x一维，</p><blockquote><p>如jpeg、傅里叶变换都是找新基，得到新特征；</p></blockquote><h1 align="center">行列式</h1><p>1、行列式：方阵的一个属性；</p><p>行列式表示向量组在空间的有向体积！</p><p>2、行列式电算：</p><blockquote><p><strong>高斯消元法化为上三角（注意不能倍乘、交换），主对角线出现0就是0</strong>；</p></blockquote><h1 align="center">特征值、特征向量</h1><p>1、特征值、特征向量：方阵的一个属性；</p><p>① 定义：<br>$$A\varepsilon {\rm{ = }}\lambda \varepsilon $(%endraw%)(%raw%)$\varepsilon  \ne \overrightarrow 0 $$<br>② 特征空间即：$\{ \overrightarrow 0 \} $∪{λ的特征向量}，即A-λI的零空间；</p><p>2、投影变换：</p><p>① 投影变换为线性变换，对应一个矩阵，即：</p><blockquote><p><strong>矩阵=投影变换=线性变换；</strong></p></blockquote><p>特征向量：经过投影变换后的向量与原来的向量在同一直线的向量；</p><p>如<br>$$A = \left( {\matrix{   0 &amp; 1  \cr    1 &amp; 0  \cr  } } \right)$$<br>表示翻转变化，关于y=x对称，此时特征向量为y=x上向量，对应特征值为1；</p><p>而y=-x上向量翻转后对应λ为-1的特征向量；</p><p>② 复数：<br>$$A{\rm{ = }}\left( {\matrix{   0 &amp; {{\rm{ - }}1}  \cr    1 &amp; 0  \cr  } } \right)$$<br>基坐标来看是旋转，直观理解没有特征向量，更不用说特征值，求出λ为复数；</p><p>③ 任意：</p><p>单位矩阵：A=I，特征值为1，特征向量为任何向量，基为<br>$$\left( {{e_i},{e_j}} \right)$$<br>④ 代数重数大于等于几何重数（特征空间的维度）；</p><p>3、矩阵相似：<br>$$A = {P^{ - 1}}BP$$<br>① 几何解释：P是一个坐标系，A变换是P坐标系下观察的B变换；</p><p>② 类似于相似三角形；</p><p>③ A和B本质是一个变换，只不过观察的坐标系不同；</p><p>④ 特例：$A = {P^{ - 1}} \wedge P$表示A变换在P坐标系下观察到的变换^；</p><p>//应用：求方阵的幂；</p><p>⑤ 为什么求矩阵的幂？</p><p>动态系统：^中的特征值反应系统各个分量的变化速率；</p><h1 align="center">对称阵、奇异值</h1><p>1、对称阵：<br>$${A^T} = A$$<br>① 特征值一定是实数！并且一定可以相似对角化—几何重数一定等于代数重数；</p><p>② 不同特征值对应特征向量正交；</p><p>③ 对称阵一定可以正交变换为对角阵；</p><p>2、奇异值：<br>如果有${A_{m \times n}}$，那么${A^T} \cdot A{\rm{ = }}C$为对称方阵，可正交对角化</p><p>有<br>$${\lambda _i} \to {\varepsilon _i}$$（已规范化）<br>其中${C_{ij}}$为A的i列乘以A的j列；</p><p>那么：<br>$${\left\| {A\overrightarrow {{\varepsilon _i}} } \right\|^2} = {(A\overrightarrow {{\varepsilon _i}} )^T}(A\overrightarrow {{\varepsilon _i}} ) = {(\overrightarrow {{\varepsilon _i}} )^T}{\lambda _i}{\varepsilon _i} = {\lambda _i}$$</p><p>① ${\lambda _i} \ge 0$，${\sigma _i} = \sqrt {{\lambda _i}} $${\lambda _i} \ge 0$表示矩阵的奇异值；<br>② 奇异值表示即向量$(A\overrightarrow {{\varepsilon _i}} )$的长度；</p><p>③ ${\rm{\{ }}A\overrightarrow {{\varepsilon _1}} {\rm{,}}A\overrightarrow {{\varepsilon _2}} ,A\overrightarrow {{\varepsilon _3}} {\rm{,}} \cdots {\rm{,}}A\overrightarrow {{\varepsilon _r}} {\rm{\} }}\;\;(\lambda i \ne 0)$表示A的列空间的一组正交基，；</p><p>④ 注意事项：奇异值是对于矩阵$ A$而言，特征值是对于${A^T} \cdot A$而言，</p><p>A的奇异值为${A^T} \cdot A$的特征值开根号！</p><p>⑤ 如果A有个$r$个${\lambda _i}$不等于0，</p><p>那么$${\rm{\{ }}A\overrightarrow {{\varepsilon _1}} {\rm{,}}A\overrightarrow {{\varepsilon _2}} ,A\overrightarrow {{\varepsilon _3}} {\rm{,}} \cdots {\rm{,}}A\overrightarrow {{\varepsilon _r}} {\rm{\} }}\;\;(\lambda i \ne 0)$$组成A的列空间的一组正交基，<br>且：${Q^T}{A^T}AQ =  \wedge ,R({A^T}A) = R( \wedge ) = r = R(A)$</p><p>那么：$${\rm{\{ }}{{A\overrightarrow {{\varepsilon _i}} } \over {{\sigma _i}}}{\rm{\} }}\;\;(\lambda i \ne 0)$$表示的列空间的一组标准正交基；</p><p>3、SVD分解：对矩阵A没有限制</p><p>① 矩阵的奇异值分解（不是矩阵的分解）：</p><p>② 形式：<br>$${A_{m \times n}} = {U_{m \times m}}{\Sigma _{m \times n}}{V^T}_{n \times n}$$<br><img src="https://cdn.jsdelivr.net/gh/Zhujie-ww/zhujie-ww.github.io/loading.gif" data-original="https://cdn.jsdelivr.net/gh/Zhujie-ww/imagebed/imagebed/正交.png" alt=""></p>${{\rm{U}}_{m \times m}}$为标准正交阵；${V^T}$是${A^T}A$的特征向量进行标准化之后的矩阵（标准正交矩阵）；Σ：奇异值矩阵：$$\Sigma {\rm{ = }}\left( {\begin{array}{*{20}{c}}{{\sigma _1}}&amp;0&amp;0\\0&amp;{{\sigma _r}}&amp;0\\0&amp;0&amp;0\end{array}} \right)$$<p>其中：${\sigma _i} \ne 0,{\sigma _i} \ge {\sigma _{i + 1}}$：<br>③ 证明<br>$A = U\Sigma {V^T} \leftarrow AV = U\Sigma  \leftarrow AV = (A\overrightarrow {{v_i}} ),U\Sigma  = (A\overrightarrow {{v_i}} ,0)$<br>④ 算法过程：</p><p>S1:求解${A^T}A$特征值、特征向量；</p><p>S2:奇异值从大到小排序，得到Σ；</p><p>S3:特征向量标准化得到矩阵<br>$V$；<br>S4:求出${u_i} = \frac{{A\overrightarrow {{\varepsilon _i}} }}{{{\sigma _i}}}$${\lambda _i}≠0$，然后施法拓展；</p><p>⑤ SVD分解应用：</p><p>应用1： 对A一个N维列向量变换：<br>$Ax = U\Sigma {V^T}x = U\Sigma {V^T}Vy = U(\Sigma y) = U\left( {\begin{array}{*{20}{c}}{{\sigma _1}{y_1}}\\{\begin{array}{*{20}{c}}{{\sigma _2}{y_2}}\\{{\sigma _r}{y_r}}\\0\end{array}}\end{array}} \right) = U({\sigma _i}{y_i})$<br>几何意义：原来的$x$在基坐标下坐标为${y_i}$，经过A变换后，在$U$坐标系下为对${y_i}$进行奇异值倍拉伸；</p><p>举例：圆—变换为-椭圆；</p><p>应用2：$A = (U\Sigma ){V^T} = ({u_1}{\sigma _1}, \cdots ,{u_r}{\sigma _r},0){V^T} = \sum\limits_1^r {{u_i}{\sigma _i}{v_i}^T} ，{\sigma _i} \ge {\sigma _{i{\rm{ + }}1}}$<br>几何意义：矩阵可以看成多个递降权值的矩阵；</p><p>//因此可以进行（图像）矩阵压缩、降噪、降维，保留大的奇异值的矩阵；</p><p>应用3： 应用于推荐系统、NLP、搜索引擎；</p><p>4、最后展望；</p><p>1、统计学：PCA，最小二乘法；</p><p>微积分：差分方程、微分方程；</p><p>2、机器学习、推荐系统、图像学、经济学；</p><p>3、对领域感兴趣去学习，再补数学，有目的；</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://zhujie-ww.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性代数" scheme="https://zhujie-ww.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>helloworld</title>
    <link href="https://zhujie-ww.github.io/posts/1300/"/>
    <id>https://zhujie-ww.github.io/posts/1300/</id>
    <published>2020-04-05T12:56:59.849Z</published>
    <updated>2020-04-16T11:20:08.151Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><pre class=" language-lang-c"><code class="language-lang-c">int main (void){printf("hello ，world！")return 0;}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="第一个程序" scheme="https://zhujie-ww.github.io/tags/%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F/"/>
    
  </entry>
  
</feed>
